{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import queue\n",
    "import Levenshtein as Lev \n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\"\n",
    "\n",
    "def train(model, total_batch_size, queue, criterion, optimizer, device, train_begin, train_loader_count, print_batch=50, teacher_forcing_ratio=1):\n",
    "    total_loss = 0.\n",
    "    total_num = 0\n",
    "    total_dist = 0\n",
    "    total_length = 0\n",
    "    total_sent_num = 0\n",
    "    batch = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    #print('train() start')\n",
    "\n",
    "    begin = epoch_begin = time.time()\n",
    "\n",
    "    while True:\n",
    "        if queue.empty():\n",
    "            pass\n",
    "            #print('queue is empty')\n",
    "\n",
    "        feats, scripts, feat_lengths, script_lengths = queue.get()\n",
    "\n",
    "        if feats.shape[0] == 0:\n",
    "            # empty feats means closing one loader\n",
    "            train_loader_count -= 1\n",
    "\n",
    "            #print('left train_loader: %d' % (train_loader_count))\n",
    "\n",
    "            if train_loader_count == 0:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        feats = feats.to(device)\n",
    "        scripts = scripts.to(device)\n",
    "\n",
    "        src_len = scripts.size(1)\n",
    "        target = scripts[:, 1:]\n",
    "\n",
    "        logit = model(feats, scripts[:,:-1], mode='train')\n",
    "\n",
    "        y_hat = logit.max(-1)[1]\n",
    "\n",
    "        loss = criterion(logit.contiguous().view(-1, logit.size(-1)), target.contiguous().view(-1))\n",
    "        total_loss += loss.item()\n",
    "        total_num += sum(feat_lengths)\n",
    "\n",
    "        display = random.randrange(0, 100) == 0\n",
    "        dist, length = get_distance(target, y_hat, display=display)\n",
    "        total_dist += dist\n",
    "        total_length += length\n",
    "\n",
    "        total_sent_num += target.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step_and_update_lr()\n",
    "        \n",
    "        if batch % print_batch == 0:\n",
    "            current = time.time()\n",
    "            elapsed = current - begin\n",
    "            epoch_elapsed = (current - epoch_begin) / 60.0\n",
    "            train_elapsed = (current - train_begin) / 3600.0\n",
    "            \n",
    "            print('batch: {:4d}/{:4d}, loss: {:.4f}, cer: {:.2f}, elapsed: {:.2f}s {:.2f}m {:.2f}h'\n",
    "                .format(batch,\n",
    "                        #len(dataloader),\n",
    "                        total_batch_size,\n",
    "                        total_loss / total_num,\n",
    "                        total_dist / total_length,\n",
    "                        elapsed, epoch_elapsed, train_elapsed))\n",
    "            \n",
    "            begin = time.time()\n",
    "\n",
    "            \n",
    "        batch += 1\n",
    "        train.cumulative_batch_count += 1\n",
    "\n",
    "    #print('train() completed')\n",
    "    return total_loss / total_num, total_dist / total_length\n",
    "\n",
    "train.cumulative_batch_count = 0\n",
    "def label_to_string(labels):\n",
    "    if len(labels.shape) == 1:\n",
    "        sent = str()\n",
    "        for i in labels:\n",
    "            if i.item() == EOS_token:\n",
    "                break\n",
    "            sent += index2char[i.item()]\n",
    "        return sent\n",
    "\n",
    "    elif len(labels.shape) == 2:\n",
    "        sents = list()\n",
    "        for i in labels:\n",
    "            sent = str()\n",
    "            for j in i:\n",
    "                if j.item() == EOS_token:\n",
    "                    break\n",
    "                sent += index2char[j.item()]\n",
    "            sents.append(sent)\n",
    "\n",
    "        return sents\n",
    "def char_distance(ref, hyp):\n",
    "    ref = ref.replace(' ', '') \n",
    "    hyp = hyp.replace(' ', '') \n",
    "\n",
    "    dist = Lev.distance(hyp, ref)\n",
    "    length = len(ref.replace(' ', ''))\n",
    "\n",
    "    return dist, length \n",
    "\n",
    "\n",
    "def get_distance(ref_labels, hyp_labels, display=False):\n",
    "    total_dist = 0\n",
    "    total_length = 0\n",
    "    for i in range(len(ref_labels)):\n",
    "        ref = label_to_string(ref_labels[i])\n",
    "        hyp = label_to_string(hyp_labels[i])\n",
    "        dist, length = char_distance(ref, hyp)\n",
    "        total_dist += dist\n",
    "        total_length += length \n",
    "        if display:\n",
    "            cer = total_dist / total_length\n",
    "            logger.debug('%d (%0.4f)\\n(%s)\\n(%s)' % (i, cer, ref, hyp))\n",
    "    return total_dist, total_length\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, queue, criterion, device):\n",
    "    #logger.info('evaluate() start')\n",
    "    total_loss = 0.\n",
    "    total_num = 0\n",
    "    total_dist = 0\n",
    "    total_length = 0\n",
    "    total_sent_num = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            feats, scripts, feat_lengths, script_lengths = queue.get()\n",
    "            if feats.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            feats = feats.to(device)\n",
    "            scripts = scripts.to(device)\n",
    "\n",
    "            src_len = scripts.size(1)\n",
    "            target = scripts[:, 1:]\n",
    "\n",
    "            logit = model(feats, scripts[:,:-1], mode='eval')\n",
    "\n",
    "            y_hat = logit.max(-1)[1]\n",
    "\n",
    "            loss = criterion(logit.contiguous().view(-1, logit.size(-1)), target.contiguous().view(-1))\n",
    "            total_loss += loss.item()\n",
    "            total_num += sum(feat_lengths)\n",
    "\n",
    "            display = random.randrange(0, 100) == 0\n",
    "            dist, length = get_distance(target, y_hat, display=display)\n",
    "            total_dist += dist\n",
    "            total_length += length\n",
    "            total_sent_num += target.size(0)\n",
    "\n",
    "    #logger.info('evaluate() completed')\n",
    "    return total_loss / total_num, total_dist / total_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import label_loader\n",
    "import random\n",
    "from loader import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import queue\n",
    "\n",
    "from models.transformer import Model\n",
    "from models.utils import ScheduledOptim\n",
    "\n",
    "DATASET_PATH = '/mnt/junhyun/DATA/ASR'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "char2index, index2char = label_loader.load_label(\"hackathon.labels\")\n",
    "SOS_token = char2index['<s>']\n",
    "EOS_token = char2index['</s>']\n",
    "PAD_token = char2index['_']\n",
    "\n",
    "\n",
    "###############################################################\n",
    "seed = 1\n",
    "#feature_size = N_FFT / 2 + 1#N_FFT: defined in loader.py\n",
    "feature_size = N_FFT / 2 #N_FFT: defined in loader.py\n",
    "\n",
    "hidden_size = 512\n",
    "layer_size = 3\n",
    "bidirectional = True\n",
    "dropout=0.2\n",
    "batch_size=32\n",
    "\n",
    "max_len = 80\n",
    "use_attention = True\n",
    "epochs = 100\n",
    "\n",
    "teacher_forcing = True\n",
    "lr = 1e-5\n",
    "##############################################################\n",
    "\n",
    "\n",
    "def split_dataset( wav_paths, script_paths, valid_ratio=0.05):\n",
    "    train_loader_count = 3\n",
    "    records_num = len(wav_paths)\n",
    "    batch_num = math.ceil(records_num / batch_size)\n",
    "\n",
    "    valid_batch_num = math.ceil(batch_num * valid_ratio)\n",
    "    train_batch_num = batch_num - valid_batch_num\n",
    "\n",
    "    batch_num_per_train_loader = math.ceil(train_batch_num / 3)\n",
    "\n",
    "    train_begin = 0\n",
    "    train_end_raw_id = 0\n",
    "    train_dataset_list = list()\n",
    "\n",
    "    for i in range(3):\n",
    "\n",
    "        train_end = min(train_begin + batch_num_per_train_loader, train_batch_num)\n",
    "\n",
    "        train_begin_raw_id = train_begin *batch_size\n",
    "        train_end_raw_id = train_end * batch_size\n",
    "\n",
    "        train_dataset_list.append(BaseDataset(\n",
    "                                        wav_paths[train_begin_raw_id:train_end_raw_id],\n",
    "                                        script_paths[train_begin_raw_id:train_end_raw_id],\n",
    "                                        SOS_token, EOS_token))\n",
    "        train_begin = train_end \n",
    "\n",
    "    valid_dataset = BaseDataset(wav_paths[train_end_raw_id:], script_paths[train_end_raw_id:], SOS_token, EOS_token)\n",
    "\n",
    "    return train_batch_num, train_dataset_list, valid_dataset\n",
    "\n",
    "\n",
    "\n",
    "model = Model(len(char2index), SOS_token, EOS_token, d_model=int(feature_size), nhead=8, max_seq_len=1024, \n",
    "                                                         num_encoder_layers=6, num_decoder_layers=6,\n",
    "                                                         enc_feedforward=2048, dec_feedforward=2048,\n",
    "                                                         dropout=0.1, padding_idx=PAD_token, device=device)\n",
    "#model.flatten_parameters()\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Model parameters : {count_parameters(model):,}')\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.data.uniform_(-0.08, 0.08)\n",
    "    \n",
    "model.to(device)\n",
    "\n",
    "optimizer = ScheduledOptim(optim.Adam(\n",
    "            filter(lambda x: x.requires_grad, model.parameters()),\n",
    "            betas=(0.9, 0.98), eps=1e-09, weight_decay=1e-3),\n",
    "            int(feature_size), 4000)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(reduction='sum', ignore_index=PAD_token).to(device)\n",
    "criterion = nn.NLLLoss(reduction='sum', ignore_index=PAD_token).to(device)\n",
    "\n",
    "\n",
    "#**************************************************************************\n",
    "data_list = os.path.join(DATASET_PATH, 'train/train_data', 'data_list.csv')\n",
    "wav_paths = list()\n",
    "script_paths = list()\n",
    "\n",
    "with open(data_list, 'r') as f:\n",
    "    for line in f:\n",
    "        # line: \"aaa.wav,aaa.label\"\n",
    "\n",
    "        wav_path, script_path = line.strip().split(',')\n",
    "        wav_paths.append(os.path.join(DATASET_PATH, 'train/train_data', wav_path))\n",
    "        script_paths.append(os.path.join(DATASET_PATH, 'train/train_data', script_path))\n",
    "target_path = os.path.join(DATASET_PATH, 'train/train_label')\n",
    "\n",
    "load_targets(target_path)\n",
    "\n",
    "#**************************************************************************\n",
    "train_batch_num, train_dataset_list, valid_dataset = split_dataset( wav_paths, script_paths, valid_ratio=0.05)\n",
    "\n",
    "\n",
    "\n",
    "train_begin = time.time()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_queue = queue.Queue(3 * 2)\n",
    "    \n",
    "    train_loader = MultiLoader(train_dataset_list, train_queue, batch_size, 3)\n",
    "    train_loader.start()\n",
    "    \n",
    "    train_loss, train_cer = train(model, train_batch_num, train_queue, criterion, optimizer, device, train_begin, 3, 10, teacher_forcing)\n",
    "    print('Epoch %d (Training) Loss %0.4f CER %0.4f' % (epoch, train_loss, train_cer))\n",
    "    train_loader.join()\n",
    "    \n",
    "    valid_queue = queue.Queue(3 * 2)\n",
    "    valid_loader = BaseDataLoader(valid_dataset, valid_queue, batch_size, 0)\n",
    "    valid_loader.start()\n",
    "\n",
    "    eval_loss, eval_cer = evaluate(model, valid_loader, valid_queue, criterion, device)\n",
    "    print('------------------------------------------------------Epoch %d (Evaluate) Loss %0.4f CER %0.4f' % (epoch, eval_loss, eval_cer))\n",
    "\n",
    "    valid_loader.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
